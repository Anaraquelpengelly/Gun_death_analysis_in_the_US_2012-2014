{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "malaria_NN_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNB7rs4ZCbeUdw9HGg3h/eX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anaraquelpengelly/Gun_death_analysis_in_the_US_2012-2014/blob/master/malaria_NN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKHz0BpzZu9L",
        "colab_type": "code",
        "outputId": "1509c53f-d112-4177-ea2e-7b93de13d771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-JTLDOja_AG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB0eQZE_ikSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.figure(figsize=(3,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TspAxVy2dJpw",
        "colab_type": "code",
        "outputId": "54c27acb-d010-4f99-f0bd-295fd846db2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0_bsq4tjE2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path=\"/content/gdrive/My Drive/train_images.zip (Unzipped Files)/train_images\"\n",
        "test_path=\"/content/gdrive/My Drive/test_images.zip (Unzipped Files)/test_images\"\n",
        "results_path=\"/content/gdrive/My Drive/Colab Notebooks\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78fXCtHrh9ap",
        "colab_type": "text"
      },
      "source": [
        "Now get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8fU6apXCk4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the data:\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_transformations = transforms.Compose([                                      \n",
        "    transforms.ToTensor(),\n",
        "    #here we use the computed means I found in script quickCode.py:\n",
        "    transforms.Normalize([0.1879,0.1499,0.1592], [0.3263, 0.2615, 0.2764])\n",
        "])\n",
        "\n",
        "#2-Load the train dataset using torchvision\n",
        "train_set = ImageFolder(root=train_path, transform=train_transformations)\n",
        "#3-create an instance of the DataLoader to hold the train images:\n",
        "#TODO remember to change the batch size later!(might have to do mini batches of 4)\n",
        "train_loader = DataLoader(train_set,batch_size=4,shuffle=True,num_workers=1)\n",
        "\n",
        "#4-Define transformations for the test set\n",
        "test_transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.1879,0.1499,0.1592], [0.3263, 0.2615, 0.2764])\n",
        "\n",
        "])\n",
        "\n",
        "#5-Load the test set, note that train is set to False\n",
        "test_set = ImageFolder(root=test_path, transform=test_transformations)\n",
        "#TODO remember to change the batch size later!(might have to do mini batches of 4)\n",
        "#6-Create a loder for the test set, note that both shuffle is set to false for the test loader\n",
        "test_loader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En1lZDu-Wq28",
        "colab_type": "code",
        "outputId": "ca897166-0de5-4bc7-eb00-5285af0629b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "images, labels=next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(images[1].shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNxs2FhzDNns",
        "colab_type": "code",
        "outputId": "daf2263d-d94c-4e23-8fdf-587302ce389c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "classes=(\"parazitised\", \"uninfected\")\n",
        "def imshow(img):\n",
        "  npimg=img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.show()\n",
        "images, labels=next(iter(train_loader))\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(\" \".join(classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAB3CAYAAAD4twBKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQ+UlEQVR4nO2dbYwd11nHfw+7xCt2pXXiICt10rxh\nBVlVocFCCRQUXirSCHA/RFWjokZVJH9pRUGVUFI+IL5RCVoagSIsKKQINZRS0SiqiIqp1ErQJHaL\nTJo0idM0ia3Eadx6Ybdaw5rDh3OO59zZe/e+7L13zpz5/6SrnTkzd+fcZ87855lnnnOOOecQQghR\nFj/SdAWEEEJMH4m7EEIUiMRdCCEKROIuhBAFInEXQogCkbgLIUSBzETczexOM3vOzE6b2f2zOIYQ\nQojB2LTz3M1sAXgeeBdwBngKuMc598xUDySEEGIgs/DcfxY47Zz7jnPuf4BHgCMzOI4QQogBzELc\nDwCvJutnQpkQQog5sdjUgc3sKHA0rP5MU/UQQogW86Zz7sf7bZiFuJ8FrkvWrw1lPTjnjgHHAMxM\nA9wIIcT4vDxowyzCMk8BB83sRjO7Angf8OgMjiOEEGIAU/fcnXNbZvZh4HFgAfi0c+5b0z6OEEKI\nwUw9FXKiSigsI4QQk3DSOXe43wb1UBVCiAKRuAshRIFI3IUQokAk7kIIUSASdyGEKBCJuxBCFEhj\nww+0lUlTR81syjURQojByHMfg930CcihP4EQojtI3EdkGuLsnJPICyHmgsR9BCTIQoi2oZj7DsxK\n1NP/q1i8EO1gEj1o8vqWuIu5McrFoZudENNB4t6HeYZh4rFKFLVJ7NjvOyXapglKbmvTpm6rSTXB\nOdeYvTst7jnF0ku58GZh01JsM092Og/DzlHX7ZzaZ1qJFDB/u3ZO3HMS9E6yBizT2/I2w/pW+Kw0\nUC/RKZrQgXl78Z3KlmmDsLehjv0YOc1zlUrEI0tUYr8U/m6GzyTH6CjRPru1Uek2Lv33RToj7tmd\n0GeAF5uuxO4ZKCapgG/WltN9AM7jPfr6doD1sP35EY7ZUWZhjxLt27V20wlxz/KEvgx8FHg/8LWG\n6zIB2y6UrdoOi0nZUm37RrK8WdvvEr1hmg18GOemZP+kDl1nljaQfafLvGPuxYt7tg30G3ihugR8\nteG6jMlAT309WY4ivBY+W8lnOZSdS76/J5QtABeT7y/iRX8jlC3RQ9e8sZSu/u5J6KKtin6hmvUJ\n3Qt8Ai9wv9RwXcZgm03X8MKceufngH1heTXZdz1ZjtvXwvJm2Df+v9S7P0+vd99H5LtE1u06Q7pq\nr6LFPWt+ATgUPgk5p6Ftu0iiIJ+jV3xXqER7i+2tbJEq9JKK/ybec99IvhO3n8eLfjzOOj1ZNU3m\nE8+TeQtV29NQcxB25bl3jbc3XYHx2BZfX8QL7kpY3qDy3vdQZcUsJn/TFMfY8qIXvpKsx1BMSvTu\n4/YOttwchEqMTtM3xGIvkbZdCE03hJ3YZssNqlDMm8DN9MbZI1HUUyGPnncU86Vk361kfZ0qRTJ9\nGbvCNq+9Xs+cbTkJbWvLudB1uxUr7m2iVWK0TiXiW8D+UBazWmI5yXIasulHvAls4p8GlvHiHb10\nqG4SUdhjmCbNkS+MrouT2B1FXha6KGbEOj67J/XSL4XyVbzAr1J524Neftbj8KmAR7GuC3skiv4q\nhbZeMSm5Pbk1/R6o+FTILHkS+FC1mvPN6HLd1vEpihfwwroUPgthfQUfF4/iXO9xmjJIlONNYz3Z\nb6u2rb5/Pb+evO05iLR3aU7pnWaWjVjuRH08mFzs12Q9ihL3nE7qjpwH/g34eNMV2ZkeW8bUxBW8\nyEexPYfPjDlPFVOvC25dlAexQhVLj/+j7tVD7w1kk6p366C6Z06b6pojsl9/ihL31rAB3AL8XNMV\nGZNUtGPsfT+V6MbMmYu1/cbNSY9PBcPqEI+5jL+5tBAJ0+6Q/QYzVNzN7NNm9oaZPZ2UXWVmXzaz\nF8LfK0O5mdmDZnbazE6Z2a2zrHxruRt4BJ/rTj4xwoGs40Mu6/iwzAWq9MUYg09HdUxz1ycZ4bFf\nbnykXh6Pua/PvpkjYRKzZBTP/W+AO2tl9wPHnXMHgeNhHeDdwMHwOQo8NJ1qDkcXynTpseclqjBI\nHP9lCZ+tsoD3nJfpHRNmN4zq6ceQTAtj7znXTUyXpsLFQ8XdOfdV4Pu14iPAw2H5YeA9SflnnOfr\nwF4zu2ZalRUNsYof6Cxmv0Qx36AS+rST0m7FfRRiNk58idvvhasQHWbSmPt+59xrYfl1fOQV4ADw\narLfmVAm2kx8UboIXB2W46QbhPL0peY8xn3pF55ZorWxdzE+bXv6mXd9d/1C1fkaj11rMztqZifM\n7MRu6yDmQPSOL1C9OI3ZKvU4+7yJTw19Yu9tEwAxGm09r/Os96Tifi6GW8LfN0L5WeC6ZL9rQ9k2\nnHPHnHOHnXOHJ6xDEWT/MhV89ksU871UA3ilL1KbIn1iUKcm0QLmJfCTivujwL1h+V7gi0n5B0LW\nzG3AWhK+ETVyFPa+L39ijD0Vzy0q0W+S5eG7CNFFhl6aZvZZ4A7gajM7A/wB8EfA58zsPvyrtveG\n3b8E3AWcBn4IfHAGdd5GGx/RchT2gaS9RKOY1rv/NznGeszS2aQaniDj8d7b2F5F+7AcGpqZ7aoS\nOfyGUcld1LfZMh3UC6oOSqu17U1SH1GyRm42V3vdPW2yYT+maNeTg0Lb6qEqdiYd6yUO9btKNXF1\nk8JeH+4gnepPiI4jcRc7c5HtvVCjgK7SrJjG/ProsS8C32yuOkKMwryehpp+oO4UuT7iDmQ9fPbi\nvfSL+B6phDKYbHiBWbEF3N50JXam7eEEsTvmqQHy3MVgLuJF/ALVfKfpoF5NdRhKnxbi1Hv1USQz\nRMI+PbJwlPqMRpoTGV8KZZFFYxyXRbynfj29ueybeOGPg4nN23tPp+ZbovdlauaZMqIQzjJ23/t5\na4DEXQwm9kaNPVIj9cmu501MeYzT7l3C34TSiboDrbypZoJsF+jnMLRgUBWJu+jPOeAVqs5L6fAC\nTXvG8fhr+OydOGrlTuPAZ4CZKTQzJeZqx4zb1E5I3GdMa72fU8Cf4EMetwAfIx9vJbbaGCra01RF\nxqdNAt/0HKCl0JQNixD3Nl0wreEU8DhcYIu9xxd9+ONBmh0gbAsfdokdqvbjnzDqQyNkjtqrmAfK\nlhH9CcO97Y2qeZYBQ8DNiTheezr8QRxjfoCw5+x15ly3SBvqKAZTjLirIU6ZX6ytfwfvJfcbATLO\nhrTbyTLq30/X40vcKPBL+DDRMtmnpA1CbbZ8mjzHxYg7eEPO2pjxGP0+/fZtLe+prb8EPEn/STIW\nmI7A1l9cpevx5nExlMdc9/rL3kCrbS+G0obz23QdixL3WTPsZDV9MqfOHbX1DbyI1z3qxWR5t957\n/ckgrseRH/fROzmH6Cw5X2851K1IcZ+FYcf9nzmc3EnoeQq5LxRegRf6t+JDM/Gl5hreg95g6MiM\nYxFFe51qPJt0ftZ4A2nJKJBtpKs2HOfJfKfv5kCLcgzGY1hGQr8TMGj/cU5WLid2KvwWPuTx78Ct\nwFuoQiAX6R2NcQkv8hcZnL3SrzNIOpTAJXxaY+x1mj4R9PtbADlmzhTVhsdglCfzaWjEvCjoMhmd\nQSciPXk5nqx5ctkWvwHcjH95uY731vdRDQV8Mz7mfolKvLfoFfLYylJhj8MWxP23qPLV4+Tb/SYD\n2WH8+Laes5wEvq02nBdtsk+RYRmYvAdbTo9V2XAIL8YxOyWOFnkJP3jYCtWgYvWeonWBXq+Vx/BO\nnAQkvqDdosrCScM9hQl7JIf651AHMT2K9Nxz8YLaTo9HeQB4kaqXavSuV8JyHNtlD9XLz3P4jkbQ\n+6I1zr+6Frav0d8rX2WkOH4pohR/RxPttxQbiooixV1Mjx6Bvz7ZsNpnOXrZ8YVrzGyByquPwr+H\nKgyzGr6TDvy1TDXz05D6lca8wzQl2lBI3MUI9PUo+7WcmBaZeuFbeA/+AFWo5Rx+nPiYH7+c/E3H\nZY8C38GsmHl58W23YU7vK3JD4i5GZqwLKc1sOZAs70/2OU8l7PupbgzpdweMZdN2URqVus2nJWYl\n2U8C358ixb1tKUttYqoe5b7wN/XMR2iRXTuH9d9bXx/1XJRst90KfIm2KTZbph8lnkAhhGfS67tU\nXSjSc69T6slrknE6gc3ymGI0r7Urtkt/5yjtsWS7FC/uJZ+83BjH1vU4cr1c5208ZK/tdD08W6y4\nd+HktZmdegkLMS263J46FXMXQoiuIHEXQogCGSruZnadmX3FzJ4xs2+Z2UdC+VVm9mUzeyH8vTKU\nm5k9aGanzeyUmd066x8hhBCil1E89y3go865Q8BtwIfM7BBwP3DcOXcQOB7WAd4NHAyfo8BDU6+1\nEEKIHRkq7s6515xz3wjL/w08i+9zeAR4OOz2MNXEbEeAzzjP14G9ZnbN1GsuhBBiIGPF3M3sBuAd\nwBPAfufca2HT61Qdyw8AryZfO0PVAV0IIcQcGDkV0sxWgH8Efsc591+13GRnZmP1YDGzo/iwjRBC\niCkzkuduZj+KF/a/c859IRSfi+GW8PeNUH4WuC75+rWhrAfn3DHn3GHn3OFJKy+EEKI/o2TLGPBX\nwLPOuU8kmx4F7g3L9wJfTMo/ELJmbgPWkvCNEEKIOWAjjEnxTuBrwH8C/xeKP4aPu38OeCvwMvBe\n59z3w83gz4A7gR8CH3TOnRhyDI3XKYQQ43NyUPRjqLjPA4m7EEJMxEBxVw9VIYQoEIm7EEIUiMRd\nCCEKROIuhBAFInEXQogCyWWyjnXguaYr0QKuBt5suhItQHYaDdlpNHK20/WDNuQi7s+pp+pwzOyE\n7DQc2Wk0ZKfRaKudFJYRQogCkbgLIUSB5CLux5quQEuQnUZDdhoN2Wk0WmmnLIYfEEIIMV1y8dyF\nEEJMkcbF3czuNLPnwoTa9w//RploIvLxMLMFM/ummT0W1m80syeCPf7ezK4I5XvC+umw/YYm6z1P\nzGyvmX3ezL5tZs+a2e1qT9sxs98N19zTZvZZM1sqoT01Ku5mtgD8OX5S7UPAPWHy7S6iicjH4yP4\n+XwjHwc+6Zz7CeAHwH2h/D7gB6H8k2G/rvAp4J+dcz8J/BTeXmpPCWZ2APht4LBz7m3AAvA+SmhP\nzrnGPsDtwOPJ+gPAA03WKZcPfvKTd+E7d10Tyq7B9wkA+AvgnmT/y/uV/sHP7nUc+GXgMcDwnUwW\nw/bL7Qp4HLg9LC+G/azp3zAHG60CL9V/q9rTNjvFOZ+vCu3jMeDXSmhPTYdlNJl2HzQR+VD+FPg9\nqslj9gEXnHNbYT21xWU7he1rYf/SuRH4HvDXIXz1l2a2jNpTD865s8AfA68Ar+Hbx0kKaE9Ni7uo\nUZ+IPN3mvLvQ6fQmM/t14A3n3Mmm65I5i8CtwEPOuXcAG1QhGEDtCSC8cziCvxm+BVjGzyLXepoW\n95Em0+4Ks5iIvEB+HvhNM/su8Ag+NPMpYK+ZxeE0UltctlPYvgqcn2eFG+IMcMY590RY/zxe7NWe\nevlV4CXn3Pecc/8LfAHfxlrfnpoW96eAg+HN9BX4FxmPNlynRtBE5KPhnHvAOXetc+4GfHv5V+fc\n+4GvAHeH3ep2iva7O+xfvLfqnHsdeNXMbglFvwI8g9pTnVeA28zsx8I1GO3U/vbUdNAfuAt4HngR\n+P2m69OgHd6Jf0Q+BfxH+NyFj+cdB14A/gW4Kuxv+EyjF/GTlx9u+jc0YLM7gMfC8k3Ak8Bp4B+A\nPaF8KayfDttvarrec7TPTwMnQpv6J+BKtae+dvpD4NvA08DfAntKaE/qoSqEEAXSdFhGCCHEDJC4\nCyFEgUjchRCiQCTuQghRIBJ3IYQoEIm7EEIUiMRdCCEKROIuhBAF8v8kmV0SlMr0WwAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "parazitised parazitised uninfected parazitised\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyNE5TtlIadU",
        "colab_type": "text"
      },
      "source": [
        "Here, I can't see the parasites in thes infected images so maybe we skip the normalisation or do the normalisation as we did before for sklearn and save the images!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHWYrkqQcSRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec43a88a-8713-4317-beba-ad39839f2df5"
      },
      "source": [
        "# Install latest Tensorflow build\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter \n",
        "%load_ext tensorboard"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16CtEKJEI7yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the NN:\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):  \n",
        "        super(LeNet, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "        nn.Conv2d(3, 6, kernel_size=5), # (N, 3, 224, 224)->(N, 6, 220, 220)\n",
        "        nn.ReLU(),\n",
        "        nn.AvgPool2d(2, stride=2), #(N, 6, 220, 220) ->(N, 6, 110, 110)\n",
        "        nn.Conv2d(6, 16, kernel_size= 5),#(N, 6, 110, 110)->(N, 6, 106, 106)\n",
        "        nn.ReLU(),\n",
        "        nn.AvgPool2d(2, stride=2)) # (N, 6, 106, 106) ->(N,16, 53, 53)\n",
        "        self.fc_model=nn.Sequential(\n",
        "            #44944=16*53*53\n",
        "        nn.Linear(44944, 120), #(N, 256)-> (N, 120)\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(120, 84), #(N, 120)->(N, 84)\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(84, 2)) #(N, 84)->(N, 2)#2 classes\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x=self.cnn_model(x)\n",
        "    #print(x.shape)\n",
        "    x=x.view(x.size(0), -1)\n",
        "    x=self.fc_model(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bYsH9iuWT3x",
        "colab_type": "text"
      },
      "source": [
        "Check the GPU is available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdnOZ4C1VhuP",
        "colab_type": "code",
        "outputId": "a2ce7d75-8eed-44f3-da33-ed875016ff96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqjZbXbxVoB7",
        "colab_type": "code",
        "outputId": "3471c259-c8b6-46de-e30d-660932a6b9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device =torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aypcSUL1WOqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the model object and move it to GPU\n",
        "net = LeNet().to(device)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "opt=optim.Adam(list(net.parameters()), lr=0.001, weight_decay=0.0001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVhwne0fa31E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to evaluate the accuracy:\n",
        "def evaluation(dataloader):\n",
        "  total, correct=0, 0\n",
        "  #keeping the network in evaluation mode\n",
        "  net.eval()\n",
        "  for data in dataloader:\n",
        "    inputs, labels=data\n",
        "    #moving the inputs and labels to GPU:\n",
        "    inputs, labels=inputs.to(device), labels.to(device)\n",
        "    outputs= net(inputs)\n",
        "    _, pred=torch.max(outputs.data, 1)\n",
        "    total+=labels.size(0)\n",
        "    correct += (pred ==labels).sum().item()\n",
        "  return 100*correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTUDA4LxprQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to save the model:\n",
        "def save_models(epoch):\n",
        "    torch.save(model.state_dict(), results_path+f\"/malaria_{epoch}.model\")\n",
        "    print(\"Chekcpoint saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N61v2CxjcAwE",
        "colab_type": "text"
      },
      "source": [
        "Simple for loop to train the model ( have to deal with this later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iR8_demegFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#increase the batch size\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZdRoUOIdmDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime as datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2hb_friRTh0",
        "colab_type": "text"
      },
      "source": [
        "Here: to save on time, maybe you want to remove the tensorboard thingy!  and the add scalar!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Parg77Agb-Qc",
        "colab_type": "code",
        "outputId": "748dbe09-fb0e-44dd-a491-5e92fcded4c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "writer = SummaryWriter('runs/malaria_experiment_2')\n",
        "best_acc=0.0\n",
        "test_acc_all=[]\n",
        "train_acc_all=[]\n",
        "train_rate=[]\n",
        "loss_arr= []\n",
        "loss_epoch_arr =[]\n",
        "max_epochs=10\n",
        "for epoch in range(max_epochs):\n",
        "  #iterate through all the batches in each epoch\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    #keeping the network in training mode\n",
        "    net.train()\n",
        "    inputs, labels=data\n",
        "    #moving the inputs and labels to GPU\n",
        "    inputs, labels=inputs.to(device), labels.to(device)\n",
        "    #clear the gradients\n",
        "    opt.zero_grad()\n",
        "    #forward pass\n",
        "    outputs=net(inputs)\n",
        "    loss=loss_fn(outputs, labels)\n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loss_arr.append(loss.item())\n",
        "    test_acc=evaluation(test_loader)\n",
        "    train_acc=evaluation(train_loader)\n",
        "  loss_epoch_arr.append(loss.item())\n",
        "  test_acc_all.append(test_acc)\n",
        "  train_acc_all.append(train_acc)\n",
        " #save models\n",
        "  if test_acc > best_acc:\n",
        "            save_models(epoch)\n",
        "            best_acc = test_acc\n",
        "\n",
        "  writer.add_scalar('training loss',\n",
        "                            loss.item() / 1000,\n",
        "                            epoch * len(train_loader) + i)\n",
        "  writer.add_scalar('test Accuracy',\n",
        "                            test_acc)\n",
        "  write.add_scalar(\"training Accuracy\",\n",
        "                   train_acc)\n",
        "\n",
        "  print(f'Epoch: {epoch}/{max_epochs}, Test acc: {evaluation(test_loader)}, Train acc: {evaluation(train_loader)}')\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(test_acc, \"b\", label=\"Test accuracy\" )\n",
        "plt.plot(train_acc, \"r\", label=\"Train accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-899b78851990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nwriter = SummaryWriter(\\'runs/malaria_experiment_2\\')\\nbest_acc=0.0\\ntest_acc_all=[]\\ntrain_acc_all=[]\\ntrain_rate=[]\\nloss_arr= []\\nloss_epoch_arr =[]\\nmax_epochs=10\\nfor epoch in range(max_epochs):\\n  #iterate through all the batches in each epoch\\n  for i, data in enumerate(train_loader, 0):\\n    #keeping the network in training mode\\n    net.train()\\n    inputs, labels=data\\n    #moving the inputs and labels to GPU\\n    inputs, labels=inputs.to(device), labels.to(device)\\n    #clear the gradients\\n    opt.zero_grad()\\n    #forward pass\\n    outputs=net(inputs)\\n    loss=loss_fn(outputs, labels)\\n    #backward pass\\n    loss.backward()\\n    opt.step()\\n    loss_arr.append(loss.item())\\n    test_acc=evaluation(test_loader)\\n    train_acc=evaluation(train_loader)\\n  loss_epoch_arr.append(loss.item())\\n  test_acc_all.append(test_acc)\\n  train_acc_all.append(train_acc)\\n #save models\\n  if test_acc > best_acc:\\n            save_models(epoch)\\n            best_acc = test_acc\\n\\n  writer.add_scalar(\\'training loss\\',\\n                            loss.item() / 1000,\\n                            epoch * len(train_loader) + i)\\n  writer.add_scalar(\\'test Accuracy\\',\\n                            test_acc)\\n  write.add_scalar(\"training Accuracy\",\\n                   train_acc)\\n\\n  print(f\\'Epoch: {epoch}/{...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-0e958c1daf68>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m#keeping the network in evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#moving the inputs and labels to GPU:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2773\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtMkA8TScsbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "plt.plot(test_acc, \"b\", label=\"Test accuracy\" )\n",
        "plt.plot(train_acc, \"r\", label=\"Train accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXkcjmObm8VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#writer.add_graph(net)\n",
        "#writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5j6f8Qj1d1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiUCNLRbd6f6",
        "colab_type": "text"
      },
      "source": [
        "TODO : \n",
        "\n",
        "> - how to reaload a model that was saved?\n",
        " \n",
        ">  - git hub!!! \n",
        "\n",
        "> - do inference with the network!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JSsCihAdlWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#helper functions for plotting loss etc on tensorboard\n",
        "\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "\n",
        "    npimg = img.cpu().numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg)\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
        "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "\n",
        "def plot_classes_preds(net, images, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 48))\n",
        "    for idx in np.arange(2):\n",
        "        ax = fig.add_subplot(1, 2, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}